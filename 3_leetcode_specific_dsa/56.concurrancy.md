# Concurrency in Dart - LeetCode Guide

## Table of Contents
1. [What is Concurrency?](#what-is-concurrency)
2. [Concurrency vs Parallelism](#concurrency-vs-parallelism)
3. [Dart's Concurrency Model](#darts-concurrency-model)
4. [Key Concepts](#key-concepts)
5. [Implementation Patterns](#implementation-patterns)
6. [LeetCode Problems](#leetcode-problems)
7. [Advanced Techniques](#advanced-techniques)
8. [Performance Analysis](#performance-analysis)
9. [Pro Tips](#pro-tips)

## What is Concurrency?

**Concurrency** is the ability to handle multiple tasks at the same time, but not necessarily executing them simultaneously. It's about dealing with lots of things at once, managing multiple computations that can be interleaved or overlapped.

### Visual Representation
```
Sequential Execution:
Task A: ████████████████
Task B:                 ████████████████
Task C:                                 ████████████████

Concurrent Execution:
Task A: ████    ████    ████    ████
Task B:     ████    ████    ████    ████
Task C:         ████    ████    ████
```

## Concurrency vs Parallelism

| Aspect | Concurrency | Parallelism |
|--------|-------------|-------------|
| **Definition** | Multiple tasks making progress | Multiple tasks executing simultaneously |
| **Hardware** | Single or multiple cores | Multiple cores required |
| **Execution** | Time-slicing, interleaved | Truly simultaneous |
| **Dart Support** | ✅ Full support | ✅ Via Isolates |

## Dart's Concurrency Model

Dart uses a **single-threaded event loop** with **asynchronous programming**:

```dart
// Event Loop Architecture
/*
┌───────────────────────────┐
┌─>│           timers          │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
│  │     pending callbacks     │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
│  │       idle, prepare       │
│  └─────────────┬─────────────┘      ┌───────────────┐
│  ┌─────────────┴─────────────┐      │   incoming:   │
│  │           poll            │<─────┤  connections, │
│  └─────────────┬─────────────┘      │   data, etc.  │
│  ┌─────────────┴─────────────┐      └───────────────┘
│  │           check           │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
└──┤      close callbacks      │
   └───────────────────────────┘
*/
```

### Key Components:

1. **Event Loop**: Single-threaded execution
2. **Microtask Queue**: High-priority tasks
3. **Event Queue**: I/O operations, timers
4. **Isolates**: True parallelism

## Key Concepts

### 1. Future and Async/Await

```dart
// Basic Future
Future<String> fetchData() async {
  await Future.delayed(Duration(seconds: 1));
  return "Data fetched";
}

// Concurrent execution
Future<void> concurrentExample() async {
  // Sequential (3 seconds total)
  String data1 = await fetchData();
  String data2 = await fetchData();
  String data3 = await fetchData();
  
  // Concurrent (1 second total)
  List<String> results = await Future.wait([
    fetchData(),
    fetchData(),
    fetchData(),
  ]);
}
```

### 2. Streams for Continuous Data

```dart
// Stream for real-time data processing
Stream<int> numberStream() async* {
  for (int i = 0; i < 10; i++) {
    await Future.delayed(Duration(milliseconds: 100));
    yield i;
  }
}

// Concurrent stream processing
Future<void> processStreams() async {
  await for (int value in numberStream()) {
    print('Processing: $value');
  }
}
```

### 3. Isolates for True Parallelism

```dart
import 'dart:isolate';

// Compute-intensive function
int heavyComputation(int n) {
  int result = 0;
  for (int i = 0; i < n; i++) {
    result += i * i;
  }
  return result;
}

// Run in separate isolate
Future<int> computeInIsolate(int n) async {
  return await Isolate.run(() => heavyComputation(n));
}
```

## Implementation Patterns

### 1. Producer-Consumer Pattern

```dart
import 'dart:async';
import 'dart:collection';

class ProducerConsumer<T> {
  final Queue<T> _buffer = Queue<T>();
  final StreamController<T> _controller = StreamController<T>();
  final int _maxSize;
  
  ProducerConsumer(this._maxSize);
  
  // Producer
  Future<void> produce(T item) async {
    if (_buffer.length < _maxSize) {
      _buffer.add(item);
      _controller.add(item);
    } else {
      // Buffer full, wait or handle overflow
      await Future.delayed(Duration(milliseconds: 10));
      await produce(item); // Retry
    }
  }
  
  // Consumer
  Stream<T> consume() => _controller.stream;
  
  void close() => _controller.close();
}

// Usage
Future<void> producerConsumerExample() async {
  final pc = ProducerConsumer<int>(5);
  
  // Producer task
  Future.microtask(() async {
    for (int i = 0; i < 10; i++) {
      await pc.produce(i);
      await Future.delayed(Duration(milliseconds: 100));
    }
    pc.close();
  });
  
  // Consumer task
  await for (int value in pc.consume()) {
    print('Consumed: $value');
    await Future.delayed(Duration(milliseconds: 200));
  }
}
```

### 2. Worker Pool Pattern

```dart
class WorkerPool {
  final int _poolSize;
  final Queue<Future<void> Function()> _taskQueue = Queue();
  int _activeTasks = 0;
  
  WorkerPool(this._poolSize);
  
  Future<T> submit<T>(Future<T> Function() task) async {
    final completer = Completer<T>();
    
    _taskQueue.add(() async {
      try {
        final result = await task();
        completer.complete(result);
      } catch (e) {
        completer.completeError(e);
      }
    });
    
    _processQueue();
    return completer.future;
  }
  
  void _processQueue() {
    while (_activeTasks < _poolSize && _taskQueue.isNotEmpty) {
      final task = _taskQueue.removeFirst();
      _activeTasks++;
      
      task().whenComplete(() {
        _activeTasks--;
        _processQueue();
      });
    }
  }
}

// Usage
Future<void> workerPoolExample() async {
  final pool = WorkerPool(3);
  
  List<Future<int>> futures = [];
  for (int i = 0; i < 10; i++) {
    futures.add(pool.submit(() async {
      await Future.delayed(Duration(seconds: 1));
      return i * i;
    }));
  }
  
  List<int> results = await Future.wait(futures);
  print('Results: $results');
}
```

### 3. Rate Limiting Pattern

```dart
class RateLimiter {
  final int _maxRequests;
  final Duration _timeWindow;
  final Queue<DateTime> _requests = Queue();
  
  RateLimiter(this._maxRequests, this._timeWindow);
  
  Future<T> execute<T>(Future<T> Function() task) async {
    await _waitIfNeeded();
    _requests.add(DateTime.now());
    return await task();
  }
  
  Future<void> _waitIfNeeded() async {
    final now = DateTime.now();
    
    // Remove old requests outside time window
    while (_requests.isNotEmpty && 
           now.difference(_requests.first) > _timeWindow) {
      _requests.removeFirst();
    }
    
    // Wait if rate limit exceeded
    if (_requests.length >= _maxRequests) {
      final oldestRequest = _requests.first;
      final waitTime = _timeWindow - now.difference(oldestRequest);
      if (waitTime > Duration.zero) {
        await Future.delayed(waitTime);
        return _waitIfNeeded();
      }
    }
  }
}

// Usage
Future<void> rateLimiterExample() async {
  final limiter = RateLimiter(5, Duration(seconds: 1));
  
  for (int i = 0; i < 20; i++) {
    await limiter.execute(() async {
      print('Request $i at ${DateTime.now()}');
      return i;
    });
  }
}
```

## LeetCode Problems

### 1. Web Crawler Multithreaded (LeetCode 1242)

```dart
import 'dart:async';

class HtmlParser {
  List<String> getUrls(String url) {
    // Mock implementation
    return ['http://example.com/page1', 'http://example.com/page2'];
  }
}

class Solution {
  Future<List<String>> crawl(String startUrl, HtmlParser htmlParser) async {
    final String hostname = Uri.parse(startUrl).host;
    final Set<String> visited = <String>{};
    final Queue<String> queue = Queue<String>();
    final List<Future<void>> futures = <Future<void>>[];
    
    queue.add(startUrl);
    visited.add(startUrl);
    
    while (queue.isNotEmpty || futures.isNotEmpty) {
      // Process current queue concurrently
      final List<String> currentBatch = [];
      while (queue.isNotEmpty && currentBatch.length < 10) {
        currentBatch.add(queue.removeFirst());
      }
      
      // Create concurrent tasks
      for (String url in currentBatch) {
        futures.add(_crawlUrl(url, hostname, htmlParser, visited, queue));
      }
      
      // Wait for batch completion
      if (futures.isNotEmpty) {
        await Future.wait(futures);
        futures.clear();
      }
    }
    
    return visited.toList();
  }
  
  Future<void> _crawlUrl(
    String url, 
    String hostname, 
    HtmlParser parser,
    Set<String> visited, 
    Queue<String> queue
  ) async {
    try {
      final List<String> urls = parser.getUrls(url);
      
      for (String newUrl in urls) {
        final Uri uri = Uri.parse(newUrl);
        if (uri.host == hostname && !visited.contains(newUrl)) {
          visited.add(newUrl);
          queue.add(newUrl);
        }
      }
    } catch (e) {
      print('Error crawling $url: $e');
    }
  }
}
```

### 2. Print in Order (LeetCode 1114)

```dart
class Foo {
  late Completer<void> _firstCompleter;
  late Completer<void> _secondCompleter;
  
  Foo() {
    _firstCompleter = Completer<void>();
    _secondCompleter = Completer<void>();
  }
  
  Future<void> first(void Function() printFirst) async {
    printFirst();
    _firstCompleter.complete();
  }
  
  Future<void> second(void Function() printSecond) async {
    await _firstCompleter.future;
    printSecond();
    _secondCompleter.complete();
  }
  
  Future<void> third(void Function() printThird) async {
    await _secondCompleter.future;
    printThird();
  }
}

// Usage
Future<void> printInOrderExample() async {
  final foo = Foo();
  
  // Simulate concurrent execution
  Future.microtask(() => foo.third(() => print('third')));
  Future.microtask(() => foo.first(() => print('first')));
  Future.microtask(() => foo.second(() => print('second')));
  
  await Future.delayed(Duration(seconds: 1));
}
```

### 3. Print FooBar Alternately (LeetCode 1115)

```dart
class FooBar {
  final int n;
  bool _fooTurn = true;
  late Completer<void> _fooCompleter;
  late Completer<void> _barCompleter;
  
  FooBar(this.n) {
    _fooCompleter = Completer<void>();
    _barCompleter = Completer<void>();
    _fooCompleter.complete(); // Start with foo
  }
  
  Future<void> foo(void Function() printFoo) async {
    for (int i = 0; i < n; i++) {
      await _fooCompleter.future;
      printFoo();
      
      _barCompleter.complete();
      if (i < n - 1) {
        _fooCompleter = Completer<void>();
      }
    }
  }
  
  Future<void> bar(void Function() printBar) async {
    for (int i = 0; i < n; i++) {
      await _barCompleter.future;
      printBar();
      
      if (i < n - 1) {
        _fooCompleter.complete();
        _barCompleter = Completer<void>();
      }
    }
  }
}

// Usage
Future<void> fooBarExample() async {
  final fooBar = FooBar(3);
  
  Future.microtask(() => fooBar.foo(() => print('foo')));
  Future.microtask(() => fooBar.bar(() => print('bar')));
  
  await Future.delayed(Duration(seconds: 1));
}
```

### 4. Building H2O (LeetCode 1117)

```dart
class H2O {
  int _hydrogenCount = 0;
  int _oxygenCount = 0;
  final Queue<Completer<void>> _hydrogenQueue = Queue();
  final Queue<Completer<void>> _oxygenQueue = Queue();
  
  Future<void> hydrogen(void Function() releaseHydrogen) async {
    final completer = Completer<void>();
    _hydrogenQueue.add(completer);
    _tryFormMolecule();
    
    await completer.future;
    releaseHydrogen();
  }
  
  Future<void> oxygen(void Function() releaseOxygen) async {
    final completer = Completer<void>();
    _oxygenQueue.add(completer);
    _tryFormMolecule();
    
    await completer.future;
    releaseOxygen();
  }
  
  void _tryFormMolecule() {
    while (_hydrogenQueue.length >= 2 && _oxygenQueue.isNotEmpty) {
      // Release 2 hydrogens and 1 oxygen
      _hydrogenQueue.removeFirst().complete();
      _hydrogenQueue.removeFirst().complete();
      _oxygenQueue.removeFirst().complete();
    }
  }
}

// Usage
Future<void> h2oExample() async {
  final h2o = H2O();
  
  // Simulate atoms arriving
  List<Future<void>> futures = [];
  
  for (int i = 0; i < 4; i++) {
    futures.add(h2o.hydrogen(() => print('H')));
  }
  
  for (int i = 0; i < 2; i++) {
    futures.add(h2o.oxygen(() => print('O')));
  }
  
  await Future.wait(futures);
}
```

### 5. Fizz Buzz Multithreaded (LeetCode 1195)

```dart
class FizzBuzz {
  final int n;
  int _current = 1;
  
  FizzBuzz(this.n);
  
  Future<void> fizz(void Function() printFizz) async {
    while (_current <= n) {
      if (_current % 3 == 0 && _current % 5 != 0) {
        printFizz();
        _current++;
      } else {
        await Future.delayed(Duration(microseconds: 1));
      }
    }
  }
  
  Future<void> buzz(void Function() printBuzz) async {
    while (_current <= n) {
      if (_current % 5 == 0 && _current % 3 != 0) {
        printBuzz();
        _current++;
      } else {
        await Future.delayed(Duration(microseconds: 1));
      }
    }
  }
  
  Future<void> fizzbuzz(void Function() printFizzBuzz) async {
    while (_current <= n) {
      if (_current % 15 == 0) {
        printFizzBuzz();
        _current++;
      } else {
        await Future.delayed(Duration(microseconds: 1));
      }
    }
  }
  
  Future<void> number(void Function(int) printNumber) async {
    while (_current <= n) {
      if (_current % 3 != 0 && _current % 5 != 0) {
        printNumber(_current);
        _current++;
      } else {
        await Future.delayed(Duration(microseconds: 1));
      }
    }
  }
}
```

## Advanced Techniques

### 1. Lock-Free Data Structures

```dart
import 'dart:async';

class LockFreeQueue<T> {
  final Queue<T> _queue = Queue<T>();
  final StreamController<T> _controller = StreamController<T>.broadcast();
  
  void enqueue(T item) {
    _queue.add(item);
    _controller.add(item);
  }
  
  T? dequeue() {
    return _queue.isEmpty ? null : _queue.removeFirst();
  }
  
  Stream<T> get stream => _controller.stream;
  
  bool get isEmpty => _queue.isEmpty;
  int get length => _queue.length;
  
  void close() => _controller.close();
}
```

### 2. Concurrent Cache Implementation

```dart
class ConcurrentCache<K, V> {
  final Map<K, V> _cache = <K, V>{};
  final Map<K, Future<V>> _pending = <K, Future<V>>{};
  final int _maxSize;
  final Queue<K> _accessOrder = Queue<K>();
  
  ConcurrentCache(this._maxSize);
  
  Future<V> get(K key, Future<V> Function() factory) async {
    // Return cached value if available
    if (_cache.containsKey(key)) {
      _updateAccessOrder(key);
      return _cache[key]!;
    }
    
    // Return pending future if already loading
    if (_pending.containsKey(key)) {
      return _pending[key]!;
    }
    
    // Start loading
    final future = factory();
    _pending[key] = future;
    
    try {
      final value = await future;
      _cache[key] = value;
      _updateAccessOrder(key);
      _evictIfNeeded();
      return value;
    } finally {
      _pending.remove(key);
    }
  }
  
  void _updateAccessOrder(K key) {
    _accessOrder.remove(key);
    _accessOrder.add(key);
  }
  
  void _evictIfNeeded() {
    while (_cache.length > _maxSize && _accessOrder.isNotEmpty) {
      final oldest = _accessOrder.removeFirst();
      _cache.remove(oldest);
    }
  }
}
```

### 3. Circuit Breaker Pattern

```dart
enum CircuitState { closed, open, halfOpen }

class CircuitBreaker<T> {
  final int _failureThreshold;
  final Duration _timeout;
  final Duration _retryDelay;
  
  CircuitState _state = CircuitState.closed;
  int _failureCount = 0;
  DateTime? _lastFailureTime;
  
  CircuitBreaker({
    required int failureThreshold,
    required Duration timeout,
    required Duration retryDelay,
  }) : _failureThreshold = failureThreshold,
       _timeout = timeout,
       _retryDelay = retryDelay;
  
  Future<T> execute(Future<T> Function() operation) async {
    if (_state == CircuitState.open) {
      if (_shouldAttemptReset()) {
        _state = CircuitState.halfOpen;
      } else {
        throw Exception('Circuit breaker is OPEN');
      }
    }
    
    try {
      final result = await operation().timeout(_timeout);
      _onSuccess();
      return result;
    } catch (e) {
      _onFailure();
      rethrow;
    }
  }
  
  void _onSuccess() {
    _failureCount = 0;
    _state = CircuitState.closed;
    _lastFailureTime = null;
  }
  
  void _onFailure() {
    _failureCount++;
    _lastFailureTime = DateTime.now();
    
    if (_failureCount >= _failureThreshold) {
      _state = CircuitState.open;
    }
  }
  
  bool _shouldAttemptReset() {
    return _lastFailureTime != null &&
           DateTime.now().difference(_lastFailureTime!) > _retryDelay;
  }
}
```

## Performance Analysis

### Time Complexity
- **Sequential Execution**: O(n × t) where n = tasks, t = time per task
- **Concurrent Execution**: O(max(t₁, t₂, ..., tₙ)) with proper parallelism
- **Overhead**: Small constant for task scheduling and context switching

### Space Complexity
- **Memory per Task**: O(stack_size) typically 2MB per isolate
- **Shared Data**: O(1) for event loop, O(n) for queues and buffers

### Benchmarking Example

```dart
import 'dart:io';

Future<void> benchmarkConcurrency() async {
  const int taskCount = 1000;
  const Duration taskDuration = Duration(milliseconds: 10);
  
  // Sequential execution
  final sequentialStart = DateTime.now();
  for (int i = 0; i < taskCount; i++) {
    await Future.delayed(taskDuration);
  }
  final sequentialTime = DateTime.now().difference(sequentialStart);
  
  // Concurrent execution
  final concurrentStart = DateTime.now();
  await Future.wait(List.generate(taskCount, (i) => 
    Future.delayed(taskDuration)
  ));
  final concurrentTime = DateTime.now().difference(concurrentStart);
  
  print('Sequential: ${sequentialTime.inMilliseconds}ms');
  print('Concurrent: ${concurrentTime.inMilliseconds}ms');
  print('Speedup: ${sequentialTime.inMilliseconds / concurrentTime.inMilliseconds}x');
}
```

## Pro Tips

### 1. **Avoid Blocking the Event Loop**
```dart
// ❌ Bad: Blocks event loop
int heavyComputation(int n) {
  int sum = 0;
  for (int i = 0; i < n; i++) {
    sum += i;
  }
  return sum;
}

// ✅ Good: Use isolates for CPU-intensive tasks
Future<int> heavyComputationAsync(int n) async {
  return await Isolate.run(() {
    int sum = 0;
    for (int i = 0; i < n; i++) {
      sum += i;
    }
    return sum;
  });
}
```

### 2. **Proper Error Handling**
```dart
Future<List<T>> robustConcurrentExecution<T>(
  List<Future<T> Function()> tasks
) async {
  final results = <T>[];
  final futures = tasks.map((task) async {
    try {
      return await task();
    } catch (e) {
      print('Task failed: $e');
      return null;
    }
  });
  
  final allResults = await Future.wait(futures);
  return allResults.whereType<T>().toList();
}
```

### 3. **Resource Management**
```dart
class ResourcePool<T> {
  final Queue<T> _available = Queue<T>();
  final Set<T> _inUse = <T>{};
  final int _maxSize;
  
  ResourcePool(List<T> resources, this._maxSize) {
    _available.addAll(resources);
  }
  
  Future<R> use<R>(Future<R> Function(T resource) operation) async {
    final resource = await _acquire();
    try {
      return await operation(resource);
    } finally {
      _release(resource);
    }
  }
  
  Future<T> _acquire() async {
    while (_available.isEmpty) {
      await Future.delayed(Duration(milliseconds: 10));
    }
    final resource = _available.removeFirst();
    _inUse.add(resource);
    return resource;
  }
  
  void _release(T resource) {
    _inUse.remove(resource);
    _available.add(resource);
  }
}
```

### 4. **Memory Optimization**
```dart
// Use streams for large datasets
Stream<ProcessedData> processLargeDataset(
  Stream<RawData> input
) async* {
  await for (final chunk in input) {
    // Process in small chunks to avoid memory issues
    yield await processChunk(chunk);
  }
}

// Batch processing for better performance
Future<List<Result>> batchProcess<T, Result>(
  List<T> items,
  Future<Result> Function(T) processor,
  {int batchSize = 10}
) async {
  final results = <Result>[];
  
  for (int i = 0; i < items.length; i += batchSize) {
    final batch = items.skip(i).take(batchSize).toList();
    final batchResults = await Future.wait(
      batch.map(processor)
    );
    results.addAll(batchResults);
  }
  
  return results;
}
```

## Summary

Concurrency in Dart is achieved through:

1. **Single-threaded Event Loop**: Non-blocking I/O operations
2. **Async/Await**: Handling asynchronous operations elegantly
3. **Futures**: Representing eventual values
4. **Streams**: Handling sequences of asynchronous events
5. **Isolates**: True parallelism for CPU-intensive tasks

**Key Benefits**:
- Improved responsiveness
- Better resource utilization
- Scalable applications
- Non-blocking I/O operations

**Common Pitfalls**:
- Blocking the event loop
- Race conditions
- Memory leaks with streams
- Improper error handling

Master these concepts to solve complex LeetCode concurrency problems efficiently!